{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construction of Advanced Trees\n",
    "\n",
    "## Reference Materials\n",
    "\n",
    "### Pruning trees\n",
    "https://en.wikipedia.org/wiki/Pruning_(decision_trees)  \n",
    "http://statweb.stanford.edu/~tibs/ElemStatLearn/ - page 308\n",
    "\n",
    "### Recent research - XGBoost\n",
    "https://arxiv.org/pdf/1603.02754v3.pdf - June 2016 paper describing algo mods to gbm\n",
    "https://github.com/dmlc/xgboost - code\n",
    "http://homes.cs.washington.edu/%7Etqchen/2016/03/10/story-and-lessons-behind-the-evolution-of-xgboost.html - UW website\n",
    "\n",
    "\n",
    "### Industrial Tree Algorithms and their Outputs\n",
    "\n",
    "Decision Trees (and by extension Random Forests) are still being researched, and so there are a number of construction algorithms for trees in circulation today. \n",
    "\n",
    "In truth, many classifiers in use today share this characteristic in common - they can be improved on, augmented, or otherwise enhanced. ** You should consider it part of your portfolio of professional skills to keep abreast of developments in all algorithms you claim to have expertise in.**\n",
    "\n",
    "### Standard algorithms: CART and C4.5\n",
    "\n",
    "The first methods of constructing trees were developed in the early 70's by statisticians studying the analysis of survey answers. You have already built an algorithm that closely follows the original:\n",
    "\n",
    "    Construct root node\n",
    "        while X is larger than one row\n",
    "            find set S = {S1, S2} that minimizes impurities\n",
    "            choose the S that minimizes the size\n",
    "            construct child nodes and pass them S\n",
    "\n",
    "The same basic algorithm is used in more modern methods, CART and C4.5, follow a similar approach, although 10-fold cross validation is used in CART. C4.5 uses a [heuristic approach](https://en.wikipedia.org/wiki/Heuristic) to validate error rates. CART uses the Gini index and C4.5 uses entropy to detect purity. In both cases, however they grow a full tree and then **prune** the tree back to reduce overfitting.\n",
    "\n",
    "### Newer algorithms: CRUISE, GUIDE, QUEST \n",
    "\n",
    "These newer (and far less common) algorithms differ from each other in that they apply significance tests before construction of child nodes. Before assigning a split, each X is tested for association with y and the most significant variable is selected. Then, an exhaustive search is performed for the split S.\n",
    "\n",
    "Every X has the same chance to be selected if each is independent of Y, therefore this method is less prone to selection bias (inadequate randomization at each node). \n",
    "\n",
    "The tree is **pruned** the same as CART.\n",
    "\n",
    "    Construct root node\n",
    "        while X is larger than one row\n",
    "           determine if X is ordered\n",
    "           convert X to an unordered variable X' by grouping values into a small number of intervals\n",
    "           perform chi-squared test of each X' vs y and compute significance\n",
    "           choose X* in X' that has the smallest significance with y\n",
    "           Find the split S* that minimizes Gini index\n",
    "           construct child nodes and pass them S*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bagging Other Models\n",
    "\n",
    "Although bagging is the primary method by which we enhance decision trees (Random Forests), bagging is essentially a universal approach to improving models and virtually any other model can be bagged. \n",
    "\n",
    "Cross-validation is often used to check the robustness of a model. In this case, we can think of bagging as a sort of \"cross-construction\" in order to produce a more robust model than would otherwise be possible (less variance at the cost of some additional bias).\n",
    "\n",
    "If a large component of sampling error is expected in the data set (or there are flaws in the sampling), bagging can be a good way of reducing model variance and overfitting, and is worthy to try in order to provide some validation to an otherwise shaky model. \n",
    "\n",
    "Bagging is not a magic power however, and cannot solve the weaknesses of a bad estimator choice or terrible data. \n",
    "\n",
    "Scikit-learn has a good implementation for bagging both [classifiers](http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.BaggingClassifier.html) and [regressors](http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.BaggingRegressor.html). In both these cases one passes the estimator class as a first class argument into the bagging function and it generates n_estimators bootstrap samples from the original.\n",
    "\n",
    "\n",
    "## QUIZ:\n",
    "Give a case example where you might bag a model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Harnesses\n",
    "\n",
    "One phrase you will hear around our campus that you may not hear everywhere (but most professionals will understand it anyway) is \"test harness.\" A \"test harness\" is an organized way of gathering data about an estimator (newly coded or otherwise) so that you have some idea of what its modeling qualities are before you haul off and try to apply it somewhere. There are typically two things that are included in a test harness (and you need both):\n",
    "\n",
    "1. Series of unit tests to ensure that the output of methods and classes within newly-written or -modified code is both predictable and correct.\n",
    "2. Series of short-form experiments on a controlled data sample (you must pick) in order to gather useful performance metrics (F-tests and confusion matrices).\n",
    "\n",
    "The former should be something that you continuously update as you write newly coded functions, and should be a main part of your consideration as you go. This means that every time you write a new function, you should be thinking about what the unit test for this might be, and have a very good idea of what it should output.\n",
    "\n",
    "The latter should be constructed when you are done passing unit tests, and usually is a separate script. You need to make informed choices about what other estimators to compare yours to, and which performance metrics are actually valid in your case. \n",
    "\n",
    "### QUIZ:\n",
    "\n",
    "How might we construct a test harness for the entropy function, $H = \\sum_{i} P(c_{i}) log{P(c_{i})}$?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
