{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DSCI6003 2.2 The *K* Nearest  Neighbors Classifier\n",
    "\n",
    "### By the end of this lecture, you will be able to:\n",
    "1. Describe the KNN Classifier in your own words\n",
    "2. Write the algorithm of KNN in pseudocode\n",
    "3. Be able to implement KNN using scikits API design\n",
    "4. (Reach Goal) Implement metrics to test KNN efficacy\n",
    "\n",
    "\n",
    "## Introduction to the Standard Classification Problem\n",
    "\n",
    "The task of a classification algorithm or *classifier* is to predict the *label* or *class* of a given unlabeled data point. Mathematically, a classifier is a function or model $f$ that predicts the class label  for a given input example ${\\bf x}$, that is\n",
    "\n",
    "$$\\hat{y} = f({\\bf x})$$\n",
    "\n",
    "The value $\\hat{y}$ belongs to a set $\\{c_1,c_2,...,c_k\\}$ and each $c_i$ is a class label.\n",
    "\n",
    "To build the model we require the *training set*, a set of points with known class labels. Once the model $f$ is known, we can automatically predict the class for any new data point. Naturally, the quality of the model is inherently determined by the quality and accuracy of the training set, an important consideration upon evaluating any implementation of a model. Due to this constraint (which is most prevalent in classification methods), it is *de riguer* to use one of a relatively small number of standardized data sets that have been tested and evaluated over many years by scientists of many stripes. \n",
    "\n",
    "Scikits has a very good sample of the standardized data sets set up to be easily accessed from the standard api, as [discussed here](http://scikit-learn.org/stable/datasets/). You would do well to familiarize yourself with this page. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fisher's Iris Data Set\n",
    "\n",
    "Following table shows an extract of the standardized Fisher's Iris dataset, originally collected and categorized by hand; the complete data forms a $150\\times 4$ data matrix. Each entity is an Iris flower, and the attributes include *sepal length*, *sepal width*, *petal length*, and *petal width* in centimeters, and the type or class of the Iris flower.\n",
    "\n",
    "<img src=\"imgs/iris_data_table.png\" width=350/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *K* Nearest  Neighbors\n",
    "\n",
    "For fixed $K$, *the KNN classifier predicts the class of $\\bf x$ as the majority class among its $K$ nearest neighbors*.\n",
    "\n",
    "<img src=\"imgs/knn_cartoon.png\"/ width=300>\n",
    "\n",
    "$K$ is a hyperparameter for the classifier. Hyperparameters differ from parameters in that the hyperparameters are the parameters for the underlying prior distribution of a model. For example:\n",
    "\n",
    "Suppose we are using a beta distribution to model the distribution of the parameter p of a Bernoulli distribution, then:\n",
    "\n",
    "p is a parameter of the underlying system (Bernoulli distribution), and\n",
    "$\\alpha$ and $\\beta$ are parameters of the prior distribution (beta distribution), hence they are hyperparameters.\n",
    "\n",
    "The predicted class can be different for different values of $K$. For binary classification tasks, odd values of $K = 1,3,5,\\cdots$ are used to avoid ties, i.e., two class labels achieving the same score. For more than two classes, ties can be broken at random. The particular case of $K = 1$ is called the *nearest-neighbour* rule, because a test point is simply assigned to the same class as the nearest point from the training set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distance Metrics\n",
    "\n",
    "As explained above, KNN assigns a class to the test point based on the majority class of $K$ nearest neighbours. In general, euclidean distance is used to find nearest neighbours, but other distance metrics can also be used.\n",
    "\n",
    "As the dimensionality of the feature space increases, the euclidean distance often becomes problematic due to the *curse of dimensionality* (discussed later). \n",
    "\n",
    "In such cases, alternative vector-based similarity measures (dot product, cosine similarity, etc) are used to find the nearest neighbours. This transforms the original metric space into one more amicable to point-to-point measurements. \n",
    "\n",
    "Another distance measure that you might consider is Mahalanobis distance.  Here's the wikipedia page on Mahalanobis distance.  https://en.wikipedia.org/wiki/Mahalanobis_distance  Mahalanobis distance attempts to weight features according to their probabilities.  On some data sets that may be important.  \n",
    "\n",
    "In general, it's probably a good idea to normalize the data at a minimum.  Here's a link to the scikit learn scaling package.  http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html  .  You have to be a little circumspect about employing any technique where the answers change with scaling.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorithm\n",
    "\n",
    "The KNN algorithm is very simple to implement, as it does not need to be trained. The training phase merely stores the training data. For each test point, we calculate the distance of that data point to every existing data point and find the $K$ closest ones. What we return is the the most common amongst the top k classification nearest to the test point. Here's the pseudocode for _K_ Nearest Neighbors:\n",
    "\n",
    "```\n",
    "kNN:\n",
    "\n",
    "    Learn:\n",
    "        Store training set T to X_train: X_train <-- T\n",
    "\n",
    "\n",
    "    Predict:\n",
    "        for every point xp in X_predict:\n",
    "            for every point x in X_train:\n",
    "                calculate the distance d in D between x and xp\n",
    "            sort D in increasing order\n",
    "            take the \"k\" items in X_train with the smallest distances to x\n",
    "            return the majority class among these k items\n",
    "```\n",
    "\n",
    "Note that for large data sets, the algorithm can take very long to classify because it has to calculate the distance between the test point and evey other point in the data!\n",
    "\n",
    "## QUIZ:\n",
    "\n",
    "What $O()$ order computation do you expect this algorithm to be? How effective will this be on a large dataset?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy and Error Rate\n",
    "\n",
    "We can assess the performance of a classifier by looking at the _error rate_ and _accuracy_ which are defined as follows. The error rate is the fraction of incorrect predictions over the testing set. Mathematically, we can express this as:\n",
    "\n",
    "$$\\text{Error Rate } = \\frac{1}{n} \\sum_{i=1}^n I(y_i \\ne \\hat{y}_i)$$\n",
    "\n",
    "where $I$ is an _indicator function_ that has the value $1$ when its argument is true, and $0$ otherwise.\n",
    "\n",
    "The accuracy of a classifier is the fraction of correct predictions over the testing set:\n",
    "\n",
    "$$\\text{Accuracy } = \\frac{1}{n} \\sum_{i=1}^n I(y_i = \\hat{y}_i) = 1 - \\text{Error Rate}$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
