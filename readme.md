DSCI6003: Machine Learning and Data Analysis
===============================================================
**Instructors:**  
* [Mike Bowles](mailto:mbowles@newhaven.edu)  
* [Jared Thompson](mailto:jared.thompson@galvanize.com)  

**Class Location:** 44 Tehama St, 3rd Floor, gU Classroom  
**Lab Time:** 2-4 weekdays  
**Class Time:** 1:00 to 4:00 PM PST M,T,Th,F  
**Office Hours:** by Appointment    

- [Description of the Course](#description-of-the-course)
- [Structure of the Class](#structure-of-the-class)
- [Resources](#resources)
- [Grading](#grading)
- [Requirements](#course-requirements)
- [Schedule](#tentative-schedule)

Description of the Course
--------------------------------------------------------------  
**MACHINE LEARNING & DATA ANALYSIS** â€“ Essential elements of Machine Learning, with a focused introduction to core supervised and unsupervised learning algorithms, statistical modeling, and key best practice techniques for building well trained models. Designed with coding lab practice to develop implementation skills.


### Prerequisites

* DSCI6001: Mathematics for Data Science 
* DSCI6002: Statistics for Data Science

Standards
--------------------------------------------------------------  
**By the end of this course, you will be able to:**


*Implement standard abstract data structures and basic object oriented programming
*Perform basic feature engineering and interpret feature interactions.
*Implement regressions for continuous and discrete variable.
*Implement and apply basic parametric and nonparametric models.
*Implement basic clustering algorithms.




Structure of the Class
--------------------------------------------------------------  
This course will employ a traditional classroom model. What that means is that notes detailing the content of a course will be given before the class. Classroom time will be devoted to covering this material in some detail, usually with added material. RATs will be given the day after. The RATs can encompass both the lecture material and laboratory/practica. Take-home exams will be a recap of the material given in the class. Most of the grade, however, will come from code review for the practica given in class. 

Grading Guideline
RAT's         -- 15%
Labs          -- 30%
Skills Tests  -- 35%
Final         -- 20%

For full credit, assignments must be turned in on time.  50% credit will be given for materials turned in up to one week late.  

Typical preparation outside of class:
1. Personal and Group Programming Exercises
2. Ask questions and raise issues in Slack channel
3. Review Exercises as given in notes

Typical structure of a class:
1. Q&A before class - 5 minutes. 
2. RAT during class - 10 minutes.
3. Discussion of RAT Answers - 5 minutes.
4. Lecture - 60 minutes.
5. Practicum - 2 hours

The practica embody a mixture of theoretical and applied aspects discussed in class. Each practicum is due on a date given for each lab assignment. The practica also count as homework and are to be worked on to completion after class. 

There will be a *final project* to review the student's mastery of the course. The final project and presentation will be individual.

#### RATs
The readiness assessment tests (RATs) are intended to ensure that students comprehended the material consumed between classes. Students unsure of their comprehension should bring questions to be addressed before the individual RAT.

#### Exercises
The RATs are meant to assess the first three levels of [Bloom's Taxonomy](http://en.wikipedia.org/wiki/Bloom's_taxonomy#Cognitive), namely knowledge, comprehension, and analysis. The exercises are meant to develop the latter three levels: analysis, synthesis, and evaluation.

Grading
----------------------
Students will be graded according to their mastery of curriculum standards. Mastery is rated on a scale from 0 to 4:

0) Unknown <br>
1) Beginning <br>
2) Developing <br>
3) Accomplished <br>
4) Exemplary <br>

Every student is expected to achieve at least a 3 on all standards. We will be using Galvanize's Mastery Tracker which can be found at [students.galvanize.com](https://students.galvanize.com).

Resources
--------------------------------------------------------------  
There is no textbook for this course. Some books may come in handy, however:
* An Introduction to Statistical Learning, by Gareth James et. al., (Available to download from http://www-bcf.usc.edu/~gareth/ISL/)
* Machine Learning: A Probabilistic Perspective, by Kevin Murphy
* Machine Learning in Action, by Peter Harrington


Course Requirements
--------------------------------------------------------------  
### Attendance
Students are required to attend every class. It is very important you attend each class. If you cannot, please let us know as early as possible. 

### Exercises and Practica
Participation in and completion of exercises and practica is a requirement for this course.

### Evaluative Exams

There will be three mid-term skills test evaluative to demonstrate comprehension of unit material as well as a two-hour comprehensive final exam at the end of the term.

There will be no make-up exams without proper documentation approved by the administration.

### Late assignments

All lab and practica are due by the end of day on the due date. If you are late to class for any reason, you will miss out on what is covered in the beginning of class, and disrupt classmates when you come in. Take whatever measures are necessary to ensure that you will be ready to turn your assignment in on time (e.g., backup all your work on a memory stick, etc.).


## Academic Integrity
As per the University's [Academic Integrity Policy and Procedures](http://www.newhaven.edu/334887.pdf):
> The University expects that all students, graduate and undergraduate, will learn in an environment where they work independently in the pursuit of knowledge, conduct themselves in an honest and ethical manner and respect the intellectual work of others. Each member of the University community has a responsibility to be familiar with the definitions contained in, and adhere to, the Academic Integrity Policy. Students are expected to be honest in their academic work. 

Violations of the Academic Integrity Policy include (but are not limited to):

1. **Cheating** -- *i.e.* Don't read off of your neighbors exams
2. **Collusion** -- Group work is encouraged *exept on evaluative exams*. When working together (on exercises, *etc.*) acknowledgement of collaboration is required.
3. **Plagiarism** -- Reusing code presented in labs and lectures is expected, but copying someone else's solution to a problem is a form of plagiarism (even if you change the formatting or variable names).

Students who are dishonest in any class assignment or exam will receive an "F" in this course.

Tentative Schedule
--------------------------------------------------------------  
1. Review of Fundamentals
    1. Review of Linear Algebra
    2. Paths and Unions
    3. Graphs and Search
    4. Dynamic Programming and Memorization
2. Introduction to Machine Learning
    1. The Machine Learning Landscape
    2. k-Nearest Neighbors
    3. The Curse of Dimensionality
    4. PCA and Dimensionality Reduction
3. Regression and Validation
    1. Regularized Regression and Introduction to Kernelization
    2. Regularized Logistic Regression
    3. Advanced Regression and Validation Procedures
    4. Advanced Regression and Model Performance Metrics
4. Estimators and Probabilistic Models
    1. Estimator Construction and Introduction to Naive Bayes
    2. Naive Bayes and its Applications
    3. Expectation-Maximization and Gaussian Mixture Models
    4. A/B Testing and the Multiarmed Bandit
5. Nonparametric Modeling and Ensemble Models
    1. Decision Trees
    2. Pruning and Optimization of Decision Trees
    3. Ensemble Models & Random Forests
    4. Random Forests
6. Boosted and Advanced Models
    1. Adaptive Boosting
    2. Gradient Boosting
    3. Feature Engineering and Selection
    4. Advanced Feature Engineering and Selection
7. Clustering
    1. k-Means
    2. k-Medoids
    3. Clustering Metrics and Evaluation
    4. Feature Enrichment through Clustering
8. SVMs and Recommenders
    1. SVMs I
    2. SVMs II
    3. Recommenders I
    4. Recommenders II

