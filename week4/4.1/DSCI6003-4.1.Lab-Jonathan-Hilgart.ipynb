{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DSCI6003 4.1 Lab\n",
    "\n",
    "\n",
    "### 1: KFold CV\n",
    "\n",
    "We will implement K-fold validation **on the training dataset** of the loan dataset.\n",
    "\n",
    "We're going to use the FICO Loan dataset. We want to predict whether or not you get approved for a loan of 12% interest rate given the FICO Score, Loan Length and Loan Amount. Here's the code to load the data:\n",
    "\n",
    "    ```python\n",
    "    import pandas as pd\n",
    "    df = pd.read_csv('data/loanf.csv')\n",
    "    y = (df['Interest.Rate'] <= 12).values\n",
    "    X = df[['FICO.Score', 'Loan.Length', 'Loan.Amount']].values\n",
    "    ```\n",
    "    \n",
    "`sklearn` has its own implementation of K-fold\n",
    "(`sklearn.cross_validation.cross_val_score()`).\n",
    "However, to ensure you have an understanding of K-fold, you will implement it\n",
    "here using the more general `KFold` class in `sklearn`.\n",
    "\n",
    "<br>\n",
    "\n",
    "1. To do this you need to manage randomly sampling **k** folds.\n",
    "\n",
    "2. Properly combining those **k** folds into a test and training set on\n",
    "   your **on the training dataset**. Outside of the k-fold, there should be\n",
    "   another set which will be referred to as the **hold-out set**.\n",
    "\n",
    "3. Train your model on your constructed training set and evaluate on the given test set\n",
    "\n",
    "3. Repeat steps __2__ and __3__ _k_ times.\n",
    "\n",
    "4. Average your results of your error metric.\n",
    "\n",
    "5. Compare the MSE for a simple **single** test/train split to your K-fold cross validated error in `4.`.\n",
    "\n",
    "6. Plot a learning curve and test vs training error curve.\n",
    "   (You might want to use: [cross_val_score](http://scikit-learn.org/stable/modules/generated/sklearn.cross_validation.cross_val_score.html) which is scikit-learn's built-in\n",
    "   function for K-fold cross validation).  See [Illustration of Learning Curves](http://www.astro.washington.edu/users/vanderplas/Astr599/notebooks/18_IntermediateSklearn) for more details.  \n",
    "\n",
    "<div style=\"background: yellow; padding:10px\">\n",
    "Once you find the optimal hyperparameters, retrain on **ALL** of your data to create your final model.\n",
    "</div>\n",
    "\n",
    "### 2: ROC Curves \n",
    "\n",
    "One of the best ways to evaluate how a classifier performs is an ROC curve. (http://en.wikipedia.org/wiki/Receiver_operating_characteristic) \n",
    "\n",
    "![](images/roc_curve.png)\n",
    "\n",
    "To understand what is actually happening with an ROC curve, we can create one ourselves.  Here is pseudo code to plot it.\n",
    "\n",
    "The `probabilities` are values in (0,1) returned from Logistic Regression. The standard default threshold is 0.5 where 0-0.5 values are interpreted as the negative class and 0.5-1 values are predicted as the positive class.\n",
    "\n",
    "The `labels` are the true values.\n",
    "\n",
    "```\n",
    "function ROC_curve(probabilities, labels):\n",
    "    Sort instances by their prediction strength (the probabilities)\n",
    "    For every instance in increasing order of probability:\n",
    "        Set the threshold to be the probability\n",
    "        Set everything above the threshold to the positive class\n",
    "        Calculate the True Positive Rate (aka sensitivity or recall)\n",
    "        Calculate the False Positive Rate (1 - specificity)\n",
    "    Return three lists: TPRs, FPRs, thresholds\n",
    "```\n",
    "\n",
    "Recall that the true positive **rate** is\n",
    "\n",
    "```\n",
    " number of true positives     number correctly predicted positive\n",
    "-------------------------- = -------------------------------------\n",
    " number of positive cases           number of positive cases\n",
    "```\n",
    "\n",
    "and the false positive **rate** is\n",
    "\n",
    "```\n",
    " number of false positives     number incorrectly predicted positive\n",
    "--------------------------- = ---------------------------------------\n",
    "  number of negative cases           number of negative cases\n",
    "```\n",
    "\n",
    "We are going to be implementing the `roc_curve` function.\n",
    "\n",
    "Here's some example code that you should be able to use to plot the ROC curve with your function. This uses a fake dataset.\n",
    "\n",
    "```python\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "X, y = make_classification(n_features=2, n_redundant=0, n_informative=2,\n",
    "                           n_clusters_per_class=2, n_samples=1000)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "probabilities = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "tpr, fpr, thresholds = roc_curve(probabilities, y_test)\n",
    "\n",
    "plt.plot(fpr, tpr)\n",
    "plt.xlabel(\"False Positive Rate (1 - Specificity)\")\n",
    "plt.ylabel(\"True Positive Rate (Sensitivity, Recall)\")\n",
    "plt.title(\"ROC plot of fake data\")\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "### 3: ROC Curve Implementation\n",
    "\n",
    "1. Write an ROC curve function to compute the above in `roc_curve.py`.\n",
    "\n",
    "    It should take as input the predicted probabilities and the true labels.\n",
    "\n",
    "2. Run the above code to verify that it's working correctly. You can also validate your correctness against [scikit-learns built-in function](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_curve.html).\n",
    "\n",
    "3. Let's see how the roc curve looks on a real dataset. We're going to use the FICO Loan dataset. We want to predict whether or not you get approved for a loan of 12% interest rate given the FICO Score, Loan Length and Loan Amount. Here's the code to load the data:\n",
    "\n",
    "    ```python\n",
    "    import pandas as pd\n",
    "    df = pd.read_csv('data/loanf.csv')\n",
    "    y = (df['Interest.Rate'] <= 12).values\n",
    "    X = df[['FICO.Score', 'Loan.Length', 'Loan.Amount']].values\n",
    "    ```\n",
    "\n",
    "    Make sure to split your data into training and testing using sklearn's [train_test_split()](http://scikit-learn.org/stable/modules/generated/sklearn.cross_validation.train_test_split.html).\n",
    "\n",
    "### 4: Case Study -- Graduate School Admissions\n",
    "\n",
    "The data we will be using is the admission data on Grad school acceptances we saw before.\n",
    "\n",
    "* `admit`: whether or not the applicant was admitted to grad. school\n",
    "* `gpa`: undergraduate GPA\n",
    "* `GRE`: score of GRE test\n",
    "* `rank`: prestige of undergraduate school (1 is highest prestige, ala Harvard)\n",
    "\n",
    "Remember, we will use the GPA, GRE, and rank of the applicants to try to predict whether or not they will be accepted into graduate school.\n",
    "\n",
    "#### 5: Treating the data with a model\n",
    "\n",
    "Now we're ready to try to fit our data with Logistic Regression and today evaluate it with a ROC curve.  Remember the following from earlier in class and use sklearn to fit a logisitc regression again:\n",
    "\n",
    "    * Use sklearn's [KFold cross validation](http://scikit-learn.org/stable/modules/generated/sklearn.cross_validation.KFold.html) and [LinearRegression](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html) to calculate the average accuracy, precision and recall.\n",
    "\n",
    "        Hint: Use sklearn's implementation of these scores in [sklearn.metrics](http://scikit-learn.org/stable/modules/classes.html#module-sklearn.metrics).\n",
    "\n",
    "    * The `rank` column is numerical, but as it has 4 buckets, we could also consider it to be categorical. Use panda's [get_dummies](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.core.reshape.get_dummies.html) to binarize the column.\n",
    "\n",
    "6. Make a plot of the ROC curve (using your function defined in Part 1).\n",
    "\n",
    "7. Is it possible to pick a threshold where TPR > 60% and FPR < 40%? What is the threshold?\n",
    "\n",
    "    *Note that even if it appears to be in the middle of the graph it doesn't make the threshold 0.5.*\n",
    "\n",
    "### 6: Using the Youden Index\n",
    "\n",
    "Youden's Index (sometimes called J statistic) is similar to the F1 score in that it is a single number that describes the performance of a classifier.\n",
    "\n",
    "$$J = Sensitivity + Specificity - 1$$\n",
    "\n",
    "$$where$$\n",
    "\n",
    "$$Sensitivity = \\frac{TP}{TP + FN}$$\n",
    "\n",
    "$$Specificity = \\frac{TN}{TN + FP}$$\n",
    "\n",
    "![](http://i.stack.imgur.com/ysM0Z.png)\n",
    "\n",
    "The J statistic ranges from 0 to 1:\n",
    "* 0 indicating that the classifier does no better than random\n",
    "* 1 indicating that the test performed perfectly\n",
    "\n",
    "It can be thought of as an improvement on the F1 score since it takes into account all of the cells in a confusion matrix.  It can also be used to find the optimal threshold for a given ROC curve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
