{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RAT 3.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Describe the following topics:\n",
    "\n",
    "1. How does best subset selection approach regularization of OLS?\n",
    "\n",
    "2. How is ridge regression similar to best subset selection?\n",
    "\n",
    "3. Outline the steps for finding variable importance with linear regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "- 1\n",
    "\n",
    "> Stepwise regression attempts to find the features that minimizes the MSE  of the linear regression. The way it works is initially, a model is fit with each features individually. The MSE is then calculated for each feature individually in a model. The feature with the lowest MSE is run in combination with every other feature and the combination with the lowest MSE is taken. This process is repeated until you reach an asymptote with your MSE (it is not improving anymore). Once you find this point, you have found the number of features as the best subset.\n",
    "\n",
    "> This appraoches regularization because your are changing the number of features in your model which determines your model complexity. Regularization methods involve a parameter that changes the model complexity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 2\n",
    "\n",
    "> Ride regression is similar to best subset selection because it attempts to find the weights of each variable that minimizes that bias of the model (by squarring the weights times an alpha constant). This is a similar approach because you are attempting to determine the best combination of feature weights to minimize the MSE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 3\n",
    "\n",
    "> TO find the variables importance with linear regression you first have to normalize your data (remove the mean of the feature and divide by the standard deivation of the feature). After this, once you have found the weights of your features you can sort them from the highest to the lowest. This will tell you the importance of your variables (since that can be directly compared on the same scale)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
